{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c94d0f77-ea22-4514-b1f4-0e92b1e3d601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federico.cassano/.pyenv/versions/3.9.19/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/federico.cassano/.pyenv/versions/3.9.19/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for livecodebench/code_generation_lite contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/livecodebench/code_generation_lite\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/Users/federico.cassano/.pyenv/versions/3.9.19/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question_title', 'question_content', 'platform', 'question_id', 'contest_id', 'contest_date', 'starter_code', 'difficulty', 'public_test_cases', 'private_test_cases', 'metadata'],\n",
       "    num_rows: 400\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "ds = datasets.load_dataset(\"livecodebench/code_generation_lite\", split=\"test\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6895c8b-02c1-45b5-abee-3ce634d5c20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def parse_date(date):\n",
    "    date_format = '%Y-%m-%dT%H:%M:%S'\n",
    "    return datetime.datetime.strptime(date, date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f1419b1-2988-4725-9ccd-08bae0d1c621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question_title', 'question_content', 'platform', 'question_id', 'contest_id', 'contest_date', 'starter_code', 'difficulty', 'public_test_cases', 'private_test_cases', 'metadata'],\n",
       "    num_rows: 202\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "cutoff = datetime.datetime(2023, 9, 30, 0, 0)\n",
    "ds_decont = ds.filter(lambda ex: parse_date(ex[\"contest_date\"]) >= cutoff)\n",
    "ds_decont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8daec100-4841-4e4b-afea-8384475accf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import zlib\n",
    "import base64\n",
    "\n",
    "\n",
    "def decode_tests(tests):\n",
    "    return json.loads(\n",
    "                pickle.loads(\n",
    "                    zlib.decompress(\n",
    "                        base64.b64decode(tests)\n",
    "                    )\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "827413e4-dbbb-4411-bb5f-c1e3b662628f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"input\": \"6\\\\nabc\\\\nacb\\\\nbac\\\\nbca\\\\ncab\\\\ncba\\\\n\", \"output\": \"YES\\\\nYES\\\\nYES\\\\nNO\\\\nNO\\\\nYES\\\\n\", \"testtype\": \"stdin\"}]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0][\"public_test_cases\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef0d4b1-1d17-47ea-a7b7-f5b355c5bbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': '1\\nabc\\n', 'output': 'YES\\n', 'testtype': 'stdin'},\n",
       " {'input': '3\\nabc\\nabc\\nabc\\n',\n",
       "  'output': 'YES\\nYES\\nYES\\n',\n",
       "  'testtype': 'stdin'},\n",
       " {'input': '5\\ncab\\nacb\\ncba\\nbac\\nbca\\n',\n",
       "  'output': 'NO\\nYES\\nYES\\nYES\\nNO\\n',\n",
       "  'testtype': 'stdin'},\n",
       " {'input': '6\\nabc\\nabc\\nabc\\nabc\\nabc\\nabc\\n',\n",
       "  'output': 'YES\\nYES\\nYES\\nYES\\nYES\\nYES\\n',\n",
       "  'testtype': 'stdin'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_tests(ds[0][\"private_test_cases\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d959100c-780c-4626-ae18-b4f4a0d81d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# format we want:\n",
    "# - question: has prompt\n",
    "# - starter_code: has starter code, if any\n",
    "# - difficulty: has difficulty\n",
    "# - input_output: has tests, with fn_name key if needed\n",
    "# - title: just for metadata\n",
    "# - source: just for metadata\n",
    "# - date: just for metadata\n",
    "# - id: for unique id\n",
    "def clean_and_push(ds, reponame):\n",
    "    cleaned_ds = []\n",
    "    for ex in tqdm(ds, total=len(ds)):\n",
    "        public_raw_tests = json.loads(ex[\"public_test_cases\"])\n",
    "        raw_tests = decode_tests(ex[\"private_test_cases\"]) + public_raw_tests\n",
    "        tests = {\"inputs\": [], \"outputs\": []}\n",
    "        public_tests = {\"inputs\": [], \"outputs\": []}\n",
    "        metadata = json.loads(ex[\"metadata\"])\n",
    "        \n",
    "        for test in raw_tests:\n",
    "            inp = test[\"input\"]\n",
    "            out = test[\"output\"]\n",
    "            \n",
    "            if \"func_name\" in metadata:\n",
    "                inp = [json.loads(i) for i in inp.split(\"\\n\")]\n",
    "                out = json.loads(out)\n",
    "            \n",
    "            tests[\"inputs\"].append(inp)\n",
    "            tests[\"outputs\"].append(out)\n",
    "\n",
    "        for test in public_raw_tests:\n",
    "            inp = test[\"input\"]\n",
    "            out = test[\"output\"]\n",
    "            \n",
    "            if \"func_name\" in metadata:\n",
    "                inp = [json.loads(i) for i in inp.split(\"\\n\")]\n",
    "                out = json.loads(out)\n",
    "            \n",
    "            public_tests[\"inputs\"].append(inp)\n",
    "            public_tests[\"outputs\"].append(out)\n",
    "    \n",
    "        if \"func_name\" in metadata:\n",
    "            name = metadata[\"func_name\"]\n",
    "            tests[\"fn_name\"] = name\n",
    "            public_tests[\"fn_name\"] = name\n",
    "            \n",
    "        \n",
    "        obj = {\n",
    "            \"question\": ex[\"question_content\"],\n",
    "            \"starter_code\": ex[\"starter_code\"],\n",
    "            \"difficulty\": ex[\"difficulty\"],\n",
    "            \"input_output\": json.dumps(tests),\n",
    "            \"public_input_output\": json.dumps(public_tests),\n",
    "            \"title\": ex[\"question_title\"],\n",
    "            \"source\": ex[\"platform\"],\n",
    "            \"date\": ex[\"contest_date\"],\n",
    "            \"id\": ex[\"question_id\"],\n",
    "        }\n",
    "        cleaned_ds.append(obj)\n",
    "        \n",
    "    cleaned_ds = datasets.Dataset.from_list(cleaned_ds)\n",
    "    print(\"pushing to: \", reponame)\n",
    "    cleaned_ds.push_to_hub(reponame, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd087c2d-ba28-452b-94e4-05beef91a50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 202/202 [00:09<00:00, 20.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pushing to:  codegenning/livecodebench_lite_filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading the dataset shards:   0%|                                                                                                                                                             | 0/3 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format:   0%|                                                                                                                                                       | 0/1 [00:00<?, ?ba/s]\u001b[A\n",
      "Creating parquet from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.01ba/s]\u001b[A\n",
      "Uploading the dataset shards:  33%|█████████████████████████████████████████████████▋                                                                                                   | 1/3 [00:03<00:06,  3.41s/it]\n",
      "Creating parquet from Arrow format:   0%|                                                                                                                                                       | 0/1 [00:00<?, ?ba/s]\u001b[A\n",
      "Creating parquet from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.08s/ba]\u001b[A\n",
      "Uploading the dataset shards:  67%|███████████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 2/3 [00:14<00:07,  7.69s/it]\n",
      "Creating parquet from Arrow format:   0%|                                                                                                                                                       | 0/1 [00:00<?, ?ba/s]\u001b[A\n",
      "Creating parquet from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/ba]\u001b[A\n",
      "Uploading the dataset shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:31<00:00, 10.61s/it]\n"
     ]
    }
   ],
   "source": [
    "clean_and_push(ds_decont, \"codegenning/livecodebench_lite_filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177595a7-b0d7-4153-84ea-b8e0eb1dc5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = datetime.datetime(2023, 9, 30, 0, 0)\n",
    "ds_cont = ds.filter(lambda ex: ex[\"contest_date\"] < cutoff)\n",
    "ds_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc54de-8309-41e5-9e62-34afe54cab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_and_push(ds_cont, \"codegenning/livecodebench_lite_contaminated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efc6d33-2aef-4139-bc4c-f3141d8d0e1d",
   "metadata": {},
   "source": [
    "# DeepSeekCoder V2 Cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4f987b4-82a8-4d85-b700-00639bd98d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federico.cassano/.pyenv/versions/3.9.19/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for livecodebench/code_generation_lite contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/livecodebench/code_generation_lite\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question_title', 'question_content', 'platform', 'question_id', 'contest_id', 'contest_date', 'starter_code', 'difficulty', 'public_test_cases', 'private_test_cases', 'metadata'],\n",
       "    num_rows: 511\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "ds = datasets.load_dataset(\"livecodebench/code_generation_lite\", split=\"test\", version_tag=\"release_v2\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a691009-b97b-4213-bcaf-eead47a7bc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question_title', 'question_content', 'platform', 'question_id', 'contest_id', 'contest_date', 'starter_code', 'difficulty', 'public_test_cases', 'private_test_cases', 'metadata'],\n",
       "    num_rows: 226\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "cutoff = datetime.datetime(2023, 12, 1, 0, 0)\n",
    "ds_decont = ds.filter(lambda ex: parse_date(ex[\"contest_date\"]) >= cutoff)\n",
    "ds_decont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c67572e-237e-47bc-97cf-312af2a114b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 226/226 [00:24<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pushing to:  codegenning/livecodebench_lite_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading the dataset shards:   0%|                                                                                                                                                             | 0/5 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format:   0%|                                                                                                                                                       | 0/1 [00:00<?, ?ba/s]\u001b[A\n",
      "Creating parquet from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.02ba/s]\u001b[A\n",
      "Uploading the dataset shards:  20%|█████████████████████████████▊                                                                                                                       | 1/5 [00:00<00:01,  2.01it/s]\n",
      "Creating parquet from Arrow format:   0%|                                                                                                                                                       | 0/1 [00:00<?, ?ba/s]\u001b[A\n",
      "Creating parquet from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.13s/ba]\u001b[A\n",
      "Uploading the dataset shards:  40%|███████████████████████████████████████████████████████████▌                                                                                         | 2/5 [00:10<00:18,  6.27s/it]\n",
      "Creating parquet from Arrow format:   0%|                                                                                                                                                       | 0/1 [00:00<?, ?ba/s]\u001b[A\n",
      "Creating parquet from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.18s/ba]\u001b[A\n",
      "Uploading the dataset shards:  60%|█████████████████████████████████████████████████████████████████████████████████████████▍                                                           | 3/5 [00:34<00:28, 14.07s/it]\n",
      "Creating parquet from Arrow format:   0%|                                                                                                                                                       | 0/1 [00:00<?, ?ba/s]\u001b[A\n",
      "Creating parquet from Arrow format: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.84s/ba]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "clean_and_push(ds_decont, \"codegenning/livecodebench_lite_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e1d2b-f22e-4330-8d12-bdca954a9c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
