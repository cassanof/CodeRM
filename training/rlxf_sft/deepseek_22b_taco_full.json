{
  "task": "sft",
  "base": "codegenning/DeepSeek-Coder-V2-Lite-Base",
  "dataset": "codegenning/finetuning-taco-plain-rlxf-dedup",
  "save_model": true,
  "save_strategy": "steps",
  "save_steps": 0.1,
  "save_final_model_output": true,
  "save_location": "/mnt/efs/federicocassano/t_models/deepseekcoder_22b_taco_plain",
  "hyperparams":
  {
      "mask_instruct": true,
      "packed": false,
      "per_device_train_batch_size": 8,
      "gradient_accumulation_steps": 2,
      "num_train_epochs": 2,
      "learning_rate": 2e-5,
      "max_length": 8192,
      "warmup_ratio": 0.01,
      "lr_scheduler_type": "linear"
  },
  "wandb":
  {
    "group": "sft",
    "project": "code_sft",
    "name": "deepseekcoder-v2-22b"
  }
}
