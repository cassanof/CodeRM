{
  "task": "ppo",
  "model_squad": {
    "lm": {
      "model_path": "/mnt/efs/federicocassano/codeprm/training/finetuning-harness/model_starcoder2_7b_generator/checkpoint-1068",
      "gen_kwargs":
      {
        "max_tokens": 4096,
        "top_p": 0.95,
        "temperature": 0.7
      }
    },
    "reward": {"model_path": "/mnt/efs/federicocassano/codeprm/training/code-scorer/model_starcoder2_7b_orm50_mse/checkpoint-1782", "is_training": false}
  },
  "dataset": "codegenning/taco-rl",
  "hyperparams":
  {
  "online": true,
  "kl_coef": 0.005,
  "global_batch_size": 512,
  "per_device_train_batch_size": 16,
  "num_train_epochs": 1,
  "gradient_accumulation_steps": 1,
  "learning_rate": 5e-6,
  "max_length": 8129,
  "logging_steps": 1,
  "warmup_ratio": 0.05,
  "eval_steps": 0.10
  },
  "wandb":
  {
    "group": "ppo",
    "project": "code_rl",
    "name": "sc2_7b_orm_7b_mse"
  }
}
